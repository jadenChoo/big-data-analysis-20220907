{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37710fa",
   "metadata": {},
   "source": [
    "# Feature Extraction - Korean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67717470",
   "metadata": {},
   "source": [
    "#### 추준호(20224224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98672ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The corpus object\n",
    "corpus = [\n",
    "    \"반얀트리 서울, 스포츠 시설 리뉴얼 기념 농구 대회 개최\",\n",
    "    \"금융위에 P2P업체 투게더펀딩·펀다 온투업 등록 신청\",\n",
    "    \"문 닫힌 롯데백화점 본점\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6748aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08045302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    doc = re.sub(r'[^\\wㄱ-ㅎ가-힣]', ' ', doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64e3d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['반얀트리 서울  스포츠 시설 리뉴얼 기념 농구 대회 개최',\n",
       " '금융위에 P2P업체 투게더펀딩 펀다 온투업 등록 신청',\n",
       " '문 닫힌 롯데백화점 본점']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [clean_doc(x) for x in corpus]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5d427",
   "metadata": {},
   "source": [
    "## Compare Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babb9c32",
   "metadata": {},
   "source": [
    "### (1) Okt - Open Korean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89189a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fbdf796",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "344e148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['반', '얀', '트리', '서울', '스포츠', '시설', '리뉴얼', '기념', '농구', '대회', '개최']\n",
      "['금융위', '에', 'P', '2', 'P', '업체', '투게더', '펀딩', '펀다', '온', '투업', '등록', '신청']\n",
      "['문', '닫힌', '롯데', '백화점', '본점']\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus:\n",
    "    tokens = okt.morphs(doc)\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb41a98",
   "metadata": {},
   "source": [
    "### (2) Hannanum - KAIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0db3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd3b9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "han = Hannanum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8bdee49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['반얀트리', '서울', '스포츠', '시설', '리뉴얼', '기념', '농구', '대회', '개최']\n",
      "['금융위', '에', 'P2P업체', '투게더펀딩', '펀다', '온투업', '등록', '신청']\n",
      "['문', '닫히', 'ㄴ', '롯데백화점', '본점']\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus:\n",
    "    tokens = han.morphs(doc)\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44720163",
   "metadata": {},
   "source": [
    "### (3) Kkma - SNU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b18226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7153ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff95da1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['반', '얀', '트리', '서울', '스포츠', '시설', '리', '뉴', '얼', '기념', '농구', '대회', '개최']\n",
      "['금융', '위', '에', 'P', '2', 'P', '업체', '투', '것', '이', '더', '펀', '딩', '펀', '다', '오', 'ㄴ', '투', '업', '등록', '신청']\n",
      "['문', '닫히', 'ㄴ', '롯데', '백화점', '본점']\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus:\n",
    "    tokens = kkma.morphs(doc)\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16978773",
   "metadata": {},
   "source": [
    "### (4) Mecab - Japan, written in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc4ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09e1feb8",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9feeb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a47bc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [\n",
    "    han.morphs(doc) for doc in corpus\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4a239bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['반얀트리', '서울', '스포츠', '시설', '리뉴얼', '기념', '농구', '대회', '개최'],\n",
       " ['금융위', '에', 'P2P업체', '투게더펀딩', '펀다', '온투업', '등록', '신청'],\n",
       " ['문', '닫히', 'ㄴ', '롯데백화점', '본점']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a8c5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = gensim.corpora.Dictionary(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f1078b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '개최')\n",
      "(1, '기념')\n",
      "(2, '농구')\n",
      "(3, '대회')\n",
      "(4, '리뉴얼')\n",
      "(5, '반얀트리')\n",
      "(6, '서울')\n",
      "(7, '스포츠')\n",
      "(8, '시설')\n",
      "(9, 'P2P업체')\n",
      "(10, '금융위')\n",
      "(11, '등록')\n",
      "(12, '신청')\n",
      "(13, '에')\n",
      "(14, '온투업')\n",
      "(15, '투게더펀딩')\n",
      "(16, '펀다')\n",
      "(17, 'ㄴ')\n",
      "(18, '닫히')\n",
      "(19, '롯데백화점')\n",
      "(20, '문')\n",
      "(21, '본점')\n"
     ]
    }
   ],
   "source": [
    "for x in lexicon.items():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59fd00",
   "metadata": {},
   "source": [
    "### (1) Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1892696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n",
      "[(9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]\n",
      "[(17, 1), (18, 1), (19, 1), (20, 1), (21, 1)]\n"
     ]
    }
   ],
   "source": [
    "for doc in tokenized_corpus:\n",
    "    vec = lexicon.doc2bow(doc)\n",
    "    print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f37f4",
   "metadata": {},
   "source": [
    "### (2) One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d758e14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n",
      "[(9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]\n",
      "[(17, 1), (18, 1), (19, 1), (20, 1), (21, 1)]\n"
     ]
    }
   ],
   "source": [
    "for doc in tokenized_corpus:\n",
    "    vec = lexicon.doc2bow(doc)\n",
    "    vec = [(x[0], 1) for x in vec]\n",
    "    print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6484e368",
   "metadata": {},
   "source": [
    "### (3) Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de591bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(dictionary=lexicon, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4923b87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.3333333333333333), (1, 0.3333333333333333), (2, 0.3333333333333333), (3, 0.3333333333333333), (4, 0.3333333333333333), (5, 0.3333333333333333), (6, 0.3333333333333333), (7, 0.3333333333333333), (8, 0.3333333333333333)]\n",
      "[(9, 0.35355339059327373), (10, 0.35355339059327373), (11, 0.35355339059327373), (12, 0.35355339059327373), (13, 0.35355339059327373), (14, 0.35355339059327373), (15, 0.35355339059327373), (16, 0.35355339059327373)]\n",
      "[(17, 0.4472135954999579), (18, 0.4472135954999579), (19, 0.4472135954999579), (20, 0.4472135954999579), (21, 0.4472135954999579)]\n"
     ]
    }
   ],
   "source": [
    "for doc in tokenized_corpus:\n",
    "    vec = lexicon.doc2bow(doc)\n",
    "    vec = tfidf[vec]\n",
    "    print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2110b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c8fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
